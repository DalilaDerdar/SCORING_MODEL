{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline to search best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "import mlflow.sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from time import time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold, learning_curve, validation_curve\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy.stats import randint\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.pipeline import Pipeline as imbPipeline\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_df = pd.read_csv('../data/sample_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape de X : (4315, 797)\n",
            "shape de y : (4315,)\n",
            "index                               0\n",
            "SK_ID_CURR                          0\n",
            "CODE_GENDER                         0\n",
            "FLAG_OWN_CAR                        0\n",
            "FLAG_OWN_REALTY                     0\n",
            "                                   ..\n",
            "CC_NAME_CONTRACT_STATUS_nan_MAX     0\n",
            "CC_NAME_CONTRACT_STATUS_nan_MEAN    0\n",
            "CC_NAME_CONTRACT_STATUS_nan_SUM     0\n",
            "CC_NAME_CONTRACT_STATUS_nan_VAR     0\n",
            "CC_COUNT                            0\n",
            "Length: 797, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## Preprocessing sample_df: scaling\n",
        "### METTRE DANS LA PIPELINE - A FAIRE\n",
        "#remplacer les valeurs infinies par des NaN\n",
        "sample_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "#sépare la cible du reste des données\n",
        "X = sample_df.drop(columns=[\"TARGET\"])\n",
        "y = sample_df['TARGET']\n",
        "print(f\"shape de X : {X.shape}\")\n",
        "print(f\"shape de y : {y.shape}\")\n",
        "\n",
        "# Remplacement des valeurs manquantes par le mode (la valeur la plus fréquente)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Standardisation des caractéristiques\n",
        "# Cela pourrait être utile pour certains modèles qui sont sensibles aux valeurs abbérantes\n",
        "scaler = RobustScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# on construit les échantillons d'apprentissage et de validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2,random_state=42, stratify=y)#stratify to preserve the proportion of target as in the original dataset\n",
        "\n",
        "\n",
        "X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
        "print(X_train_df.isnull().sum())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing model optimizations...\n",
            "\n",
            "Estimator: Logistic Regression\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params: {'clf__C': 0.1, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
            "Best training accuracy: 0.673\n",
            "Test set accuracy score for best params: 0.701 \n",
            "\n",
            "Estimator: Decision Tree\n",
            "Best params: {'clf__criterion': 'entropy', 'clf__max_depth': 5, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 5}\n",
            "Best training accuracy: 0.628\n",
            "Test set accuracy score for best params: 0.521 \n",
            "\n",
            "Estimator: Random Forest\n",
            "Best params: {'clf__criterion': 'entropy', 'clf__max_depth': 7, 'clf__min_samples_leaf': 9, 'clf__min_samples_split': 9}\n",
            "Best training accuracy: 0.721\n",
            "Test set accuracy score for best params: 0.689 \n",
            "\n",
            "Estimator: Support Vector Machine\n"
          ]
        }
      ],
      "source": [
        "# Créez vos pipelines\n",
        "pipe_lr = Pipeline([('clf', LogisticRegression())])\n",
        "pipe_dt = Pipeline([('clf', DecisionTreeClassifier())])\n",
        "pipe_rf = Pipeline([('clf', RandomForestClassifier())])\n",
        "pipe_svm = Pipeline([('clf', SVC())])\n",
        "\n",
        "# Set grid search params\n",
        "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "param_range_fl = [1.0, 0.5, 0.1]\n",
        "\n",
        "grid_params_lr = [{'clf__penalty': ['l1', 'l2'],\n",
        "                   'clf__C': param_range_fl,\n",
        "                   'clf__solver': ['liblinear']}] \n",
        "\n",
        "grid_params_dt = [{'clf__criterion': ['gini', 'entropy'],\n",
        "                   'clf__min_samples_leaf': param_range,\n",
        "                   'clf__max_depth': param_range,\n",
        "                   'clf__min_samples_split': param_range[1:]}]\n",
        "\n",
        "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],\n",
        "                   'clf__min_samples_leaf': param_range,\n",
        "                   'clf__max_depth': param_range,\n",
        "                   'clf__min_samples_split': param_range[1:]}]\n",
        "\n",
        "grid_params_svm = [{'clf__kernel': ['linear', 'rbf'], \n",
        "                    'clf__C': param_range}]\n",
        "\n",
        "# Construct grid searches\n",
        "jobs = -1\n",
        "\n",
        "gs_lr = GridSearchCV(estimator=pipe_lr,\n",
        "                     param_grid=grid_params_lr,\n",
        "                     scoring='roc_auc',\n",
        "                     cv=10) \n",
        "\n",
        "gs_dt = GridSearchCV(estimator=pipe_dt,\n",
        "                     param_grid=grid_params_dt,\n",
        "                     scoring='roc_auc',\n",
        "                     cv=10,\n",
        "                     n_jobs=jobs)\n",
        "\n",
        "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
        "                     param_grid=grid_params_rf,\n",
        "                     scoring='roc_auc',\n",
        "                     cv=10, \n",
        "                     n_jobs=jobs)\n",
        "\n",
        "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
        "                      param_grid=grid_params_svm,\n",
        "                      scoring='roc_auc',\n",
        "                      cv=10,\n",
        "                      n_jobs=jobs)\n",
        "\n",
        "# List of pipelines for ease of iteration\n",
        "grids = [gs_lr, gs_dt, gs_rf, gs_svm]\n",
        "\n",
        "# Dictionary of pipelines and classifier types for ease of reference\n",
        "grid_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'Random Forest', 3: 'Support Vector Machine'}\n",
        "\n",
        "# Fit the grid search objects\n",
        "print('Performing model optimizations...')\n",
        "best_auc = 0.0\n",
        "best_clf = 0\n",
        "best_gs = ''\n",
        "\n",
        "for idx, gs in enumerate(grids):\n",
        "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
        "    gs.fit(X_train, y_train)\n",
        "    print('Best params: %s' % gs.best_params_)\n",
        "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
        "    # Predict on test data with best params\n",
        "    y_pred_proba = gs.predict_proba(X_test)[:, 1]\n",
        "    # Test data accuracy of model with best params\n",
        "    print('Test set accuracy score for best params: %.3f ' % roc_auc_score(y_test, y_pred_proba))\n",
        "    # Track best (highest test accuracy) model\n",
        "    if roc_auc_score(y_test, y_pred_proba) > best_auc:\n",
        "        best_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        best_gs = gs\n",
        "        best_clf = idx\n",
        "print('\\nClassifier with best test set AUC: %s' % grid_dict[best_clf])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize classifiers\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "forest = RandomForestClassifier(random_state=42)\n",
        "svm = SVC(random_state=42, probability=True)\n",
        "\n",
        "# Define the hyperparameters\n",
        "hyperparameters = {\n",
        "    logreg: {\n",
        "        'C': np.logspace(-4, 4, 20),\n",
        "        'solver': ['liblinear']\n",
        "    },\n",
        "    tree: {\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'max_depth': range(1, 10),\n",
        "        'min_samples_split': range(2, 10),\n",
        "        'min_samples_leaf': range(1, 10)\n",
        "    },\n",
        "    forest: {\n",
        "        'n_estimators': range(10, 101, 10),\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'max_depth': range(1, 10),\n",
        "        'min_samples_split': range(2, 10),\n",
        "        'min_samples_leaf': range(1, 10)\n",
        "    },\n",
        "    svm: {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'gamma': [1, 0.1, 0.01, 0.001],\n",
        "        'kernel': ['rbf', 'poly', 'sigmoid']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Initialize the DataFrame for storing the results\n",
        "results = []\n",
        "\n",
        "# Loop through the classifiers\n",
        "for classifier, params in hyperparameters.items():\n",
        "    start = time()\n",
        "    classifier_name = classifier.__class__.__name__\n",
        "    \n",
        "    gs = RandomizedSearchCV(classifier, params, scoring='roc_auc', cv=5, n_iter=10, n_jobs=-1, random_state=42)\n",
        "    gs.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict the target for the testing data\n",
        "    y_pred = gs.predict(X_test)\n",
        "    \n",
        "    # Calculate the metrics\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    \n",
        "    # Store the results in a DataFrame\n",
        "    results.append({\n",
        "        'Model': classifier_name,\n",
        "        'Best Parameters': gs.best_params_,\n",
        "        'Execution Time (s)': time() - start,\n",
        "        'Training AUC': gs.best_score_,\n",
        "        'Testing AUC': auc,\n",
        "        'Testing Accuracy': acc,\n",
        "        'Testing F1 Score': f1\n",
        "    })\n",
        "\n",
        "# Convert the results to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline 3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 3.1 : tous les modèles avec paramètres par défaut "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Execution time: 352.74126839637756 ms\n",
            "\n",
            "Best parameters:  {'clf__n_estimators': 100, 'clf__max_depth': 20, 'clf': RandomForestClassifier(max_depth=20, random_state=42)}\n",
            "\n",
            "Best training AUC:  0.6817312086060937\n",
            "\n",
            "                    Model                                    Best Parameters  \\\n",
            "0  RandomForestClassifier  {'clf__n_estimators': 100, 'clf__max_depth': 2...   \n",
            "\n",
            "   Training AUC  Test AUC  Precision  Recall  F1 Score  \n",
            "0      0.681731  0.642857        0.0     0.0       0.0  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dalila.derdar.ONCEFORALL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Initialize the classifiers\n",
        "clf1 = LogisticRegression(random_state=42)\n",
        "clf2 = DecisionTreeClassifier(random_state=42)\n",
        "clf3 = RandomForestClassifier(random_state=42)\n",
        "clf4 = SVC(random_state=42, probability=True)\n",
        "clf5 = KNeighborsClassifier()\n",
        "\n",
        "# Initialize the hyperparameters for each dictionary\n",
        "param1 = {'clf__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'clf__penalty': ['l2'], 'clf': [clf1]}\n",
        "param2 = {'clf__max_depth': [None, 5, 10, 15, 20], 'clf__min_samples_split': [2, 5, 10], 'clf': [clf2]}\n",
        "param3 = {'clf__n_estimators': [10, 50, 100, 200], 'clf__max_depth': [None, 5, 10, 15, 20], 'clf': [clf3]}\n",
        "param4 = {'clf__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'clf__gamma': ['scale', 'auto'], 'clf': [clf4]}\n",
        "param5 = {'clf__n_neighbors': [3, 5, 7, 9, 11], 'clf': [clf5]}\n",
        "\n",
        "## rajouter ici les preprocessing\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline([('clf', clf1)])\n",
        "params = [param1, param2, param3, param4, param5]\n",
        "\n",
        "#Demander de calculer d'autres métrics sur le valide set\n",
        "scorings = ['roc_auc', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Use RandomizedSearchCV to find the best parameters\n",
        "gs = RandomizedSearchCV(pipeline, params, n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = -1, scoring=scorings,refit='roc_auc', return_train_score=True)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Fit the model\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "print(\"Execution time: \" + str((time.time() - start)) + ' ms')\n",
        "print()\n",
        "print(\"Best parameters: \", gs.best_params_)\n",
        "print()\n",
        "print(\"Best training AUC: \", gs.best_score_)\n",
        "print()\n",
        "# Predict the labels of the test set\n",
        "y_pred = gs.predict(X_test)\n",
        "\n",
        "# Calculate the probabilities for the test set\n",
        "y_pred_proba = gs.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute the AUC score, precision, recall, and F1 score\n",
        "auc_test = roc_auc_score(y_test, y_pred_proba)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Store the results in a DataFrame\n",
        "results = pd.DataFrame({\n",
        "    'Model': [gs.best_params_['clf'].__class__.__name__],\n",
        "    'Best Parameters': [gs.best_params_],\n",
        "    'Training AUC': [gs.best_score_],\n",
        "    'Test AUC': [auc_test],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1]\n",
        "})\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[793,   0],\n",
              "       [ 70,   0]], dtype=int64)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm_1 = confusion_matrix(y_test, y_pred)\n",
        "cm_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Best Parameters</th>\n",
              "      <th>Training AUC</th>\n",
              "      <th>Test AUC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>{'clf__n_estimators': 100, 'clf__max_depth': 2...</td>\n",
              "      <td>0.681731</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Model                                    Best Parameters  \\\n",
              "0  RandomForestClassifier  {'clf__n_estimators': 100, 'clf__max_depth': 2...   \n",
              "\n",
              "   Training AUC  Test AUC  Precision  Recall  F1 Score  \n",
              "0      0.681731  0.642857        0.0     0.0       0.0  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 3.2 : recherche des meilleurs hyerparamètres sur le meilleur modèle randomforest"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pipeline 3-2-1 recherche des meilleurs hyerparamètres sur le meilleur modèle randomforest - score roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters:  {'class_weight': 'balanced', 'max_depth': 14, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 155}\n",
            "                    Model                                    Best Parameters  \\\n",
            "0  RandomForestClassifier  {'class_weight': 'balanced', 'max_depth': 14, ...   \n",
            "\n",
            "   Training AUC  Test AUC  Precision    Recall  F1 Score  \n",
            "0      0.710788  0.685246   0.333333  0.071429  0.117647  \n"
          ]
        }
      ],
      "source": [
        "#Réentrainer avec plus d'hyperparamètres de Random Forest\n",
        "\n",
        "# Define the hyperparameters\n",
        "param_dist = {\n",
        "    'n_estimators': randint(10, 200),\n",
        "    'max_depth': randint(1, 20),\n",
        "    'class_weight': ['balanced', None],\n",
        "    'min_samples_split': randint(2, 10),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Initialize the classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "scorings = ['roc_auc', 'precision', 'recall', 'f1']\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, cv=5, n_jobs=-1, scoring= scorings, refit= 'roc_auc')\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters: \", random_search.best_params_)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = random_search.predict(X_test)\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred_proba = random_search.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Store the results in a DataFrame\n",
        "results = pd.DataFrame({\n",
        "    'Model': [random_search.best_estimator_.__class__.__name__],\n",
        "    'Best Parameters': [random_search.best_params_],\n",
        "    'Training AUC': [random_search.best_score_],\n",
        "    'Test AUC': [auc],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1]\n",
        "})\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[783  10]\n",
            " [ 65   5]]\n"
          ]
        }
      ],
      "source": [
        "#afficher la matrice de confusion pour le meilleur modèle\n",
        "#matrice de confusion\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pipeline 3-2-2 recherche des meilleurs hyerparamètres sur le meilleur modèle randomforest - score recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters:  {'class_weight': 'balanced', 'max_depth': 2, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 195}\n",
            "                    Model                                    Best Parameters  \\\n",
            "0  RandomForestClassifier  {'class_weight': 'balanced', 'max_depth': 2, '...   \n",
            "\n",
            "   Training AUC  Test AUC  Precision    Recall  F1 Score  \n",
            "0      0.572338  0.696379   0.131429  0.657143  0.219048  \n"
          ]
        }
      ],
      "source": [
        "#Réentrainer avec plus d'hyperparamètres de Random Forest\n",
        "\n",
        "# Define the hyperparameters\n",
        "param_dist = {\n",
        "    'n_estimators': randint(10, 200),\n",
        "    'max_depth': randint(1, 20),\n",
        "    'class_weight': ['balanced', None],\n",
        "    'min_samples_split': randint(2, 10),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Initialize the classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "scorings = ['roc_auc', 'precision', 'recall', 'f1']\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, cv=5, n_jobs=-1, scoring= scorings, refit= 'recall')\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters: \", random_search.best_params_)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = random_search.predict(X_test)\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred_proba = random_search.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Store the results in a DataFrame\n",
        "results = pd.DataFrame({\n",
        "    'Model': [random_search.best_estimator_.__class__.__name__],\n",
        "    'Best Parameters': [random_search.best_params_],\n",
        "    'Training AUC': [random_search.best_score_],\n",
        "    'Test AUC': [auc],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1]\n",
        "})\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[489 304]\n",
            " [ 24  46]]\n"
          ]
        }
      ],
      "source": [
        "#afficher la matrice de confusion pour le meilleur modèle\n",
        "#matrice de confusion\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 3-3 modification des hyperparamètres du meilleur modèle randomforest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters:  {'class_weight': None, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 9, 'n_estimators': 148}\n",
            "                    Model                                    Best Parameters  \\\n",
            "0  RandomForestClassifier  {'class_weight': None, 'max_depth': 10, 'max_f...   \n",
            "\n",
            "   Training AUC  Test AUC  Precision    Recall  F1 Score  \n",
            "0      0.919758   0.71207     0.3125  0.071429  0.116279  \n"
          ]
        }
      ],
      "source": [
        "#Réentrainer avec changement de seuil de décision à 0.3\n",
        "\n",
        "# Define the hyperparameters\n",
        "param_dist = {\n",
        "    'n_estimators': randint(10, 200),\n",
        "    'max_depth': randint(1, 20),\n",
        "    'class_weight': ['balanced', None],\n",
        "    'min_samples_split': randint(2, 10),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Initialize the classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters: \", random_search.best_params_)\n",
        "\n",
        "# Predict the labels of the test set with a different threshold\n",
        "y_pred_proba = random_search.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_pred_proba >= 0.3).astype(int)\n",
        "\n",
        "# Evaluate on the test set\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Store the results in a DataFrame\n",
        "results = pd.DataFrame({\n",
        "    'Model': [random_search.best_estimator_.__class__.__name__],\n",
        "    'Best Parameters': [random_search.best_params_],\n",
        "    'Training AUC': [random_search.best_score_],##ce n'est pas le score train score mais le score de validation. Plutôt faire y_train_pred = random_search.predict(X_train) \n",
        "    'Test AUC': [auc],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1]\n",
        "})\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le score d'AUC pour le jeu d'entraînement est de 0.92, ce qui indique que le modèle est capable de distinguer efficacement les remboursements des non-remboursements sur le jeu de données d'entraînement. Cependant, le score d'AUC pour le jeu de test est de 0.71, ce qui est significativement plus bas. Cela peut indiquer que le modèle surapprend sur le jeu de données d'entraînement (overfitting) et ne généralise pas bien aux nouvelles données.\n",
        "\n",
        "La précision est de 0.31, ce qui signifie que seulement 31% des prêts que le modèle prédit comme étant en défaut (1 = ne peut pas rembourser) sont effectivement en défaut. En d'autres termes, beaucoup de prêts qui auraient pu être remboursés sont refusés par le modèle.\n",
        "\n",
        "Le recall est de 0.071, ce qui signifie que le modèle est seulement capable de détecter environ 7.1% des défauts de remboursement. En d'autres termes, le modèle laisse passer environ 93% des défauts de remboursement, ce qui est très problématique car cela signifie que beaucoup de prêts qui ne seront pas remboursés sont accordés.\n",
        "\n",
        "Le score F1 est une moyenne harmonique de la précision et du rappel, et il est généralement plus utile que la précision lorsque vous avez une répartition inégale des classes (c'est-à-dire beaucoup plus de remboursements que de défauts de remboursement). Un score F1 de 0.116 est assez faible, ce qui indique que le modèle ne parvient pas à trouver un bon équilibre entre précision et rappel.\n",
        "\n",
        "ces résultats suggèrent que votre modèle a du mal à identifier les défauts de remboursement, et il est probablement trop prudent en refusant beaucoup de prêts qui seraient effectivement remboursés. Cela pourrait être dû à une sous-représentation des défauts de remboursement dans les données, ou à un seuil de décision qui est trop élevé.\n",
        "\n",
        "Essayer le rééquilibrage des classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 3-4 Randomforest et test hyperparamètres - intégration preprocessing + ML FLow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/07/10 16:51:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a6d4f388e5094b62938ca6fffa1838ec', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape de X : (4315, 797)\n",
            "shape de y : (4315,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/07/10 16:51:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/10 16:51:43 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
            "2023/07/10 16:51:43 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not specify a `predict` function, which is required in order to infer the signature\n",
            "2023/07/10 16:51:43 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
            "2023/07/10 16:51:52 INFO mlflow.tracking.fluent: Experiment with name 'Scoring_models' does not exist. Creating a new experiment.\n",
            "2023/07/10 16:51:52 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
            "2023/07/10 16:51:53 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
            "2023/07/10 16:54:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\sklearn\\utils.py:788: UserWarning: Top 5 child runs will be created based on ordering in rank_test_roc_auc column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
            "2023/07/10 16:54:17 INFO mlflow.sklearn.utils: Logging the 5 best runs, 5 runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    Model                                    Best Parameters  \\\n",
            "0  RandomForestClassifier  {'class_weight': 'balanced', 'max_depth': 2, '...   \n",
            "\n",
            "   Training AUC  Test AUC  Precision    Recall  F1 Score  Training Recall  \\\n",
            "0      0.417208  0.657737   0.153846  0.485714  0.233677         0.640288   \n",
            "\n",
            "   Validation Recall  Test Recall  \n",
            "0           0.417208     0.485714  \n"
          ]
        }
      ],
      "source": [
        "# Lire les données\n",
        "sample_df = pd.read_csv('../data/sample_df.csv')\n",
        "\n",
        "# Remplacer les valeurs infinies par des NaN\n",
        "sample_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Séparer la cible du reste des données\n",
        "X = sample_df.drop(columns=[\"TARGET\"])\n",
        "y = sample_df['TARGET']\n",
        "print(f\"shape de X : {X.shape}\")\n",
        "print(f\"shape de y : {y.shape}\")\n",
        "\n",
        "# Construire le pipeline de prétraitement\n",
        "preprocessor = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('scaler', RobustScaler())\n",
        "])\n",
        "\n",
        "# Application du prétraitement et split du dataset\n",
        "X = preprocessor.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "###Setup MLFLOW\n",
        "mlflow.set_experiment('Scoring_models')\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Définir les hyperparamètres\n",
        "param_dist = {\n",
        "    'n_estimators': randint(10, 200),\n",
        "    'max_depth': randint(1, 20),\n",
        "    'class_weight': ['balanced', None],\n",
        "    'min_samples_split': randint(2, 10),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Initialiser le classifieur\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "scorings = ['roc_auc', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Initialiser RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, cv=5, n_jobs=-1, scoring=scorings, refit='recall')\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run(run_name='test_1'):\n",
        "\n",
        "    # Entraîner le modèle\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Calculate train score\n",
        "    train_score = recall_score(y_train, best_model.predict(X_train))\n",
        "\n",
        "    # Calculate validation score (best_score_ is already based on validation set because we're using cross-validation in RandomizedSearchCV)\n",
        "    validation_score = random_search.best_score_\n",
        "\n",
        "    # Prédire les labels de l'ensemble de test\n",
        "    y_pred = random_search.predict(X_test)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_score = recall_score(y_test, y_pred)\n",
        "\n",
        "    # Evaluer sur l'ensemble de test\n",
        "    y_pred_proba = random_search.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Log the parameters\n",
        "    mlflow.log_params(random_search.best_params_)\n",
        "\n",
        "\n",
        "    # Log the metrics\n",
        "    mlflow.log_metric(\"Training Recall\", train_score)\n",
        "    mlflow.log_metric(\"Validation Recall\", validation_score)\n",
        "    mlflow.log_metric(\"Test Recall\", test_score)\n",
        "    mlflow.log_metric(\"Test AUC\", auc)\n",
        "    mlflow.log_metric(\"Precision\", precision)\n",
        "    mlflow.log_metric(\"Recall\", recall)\n",
        "    mlflow.log_metric(\"F1 Score\", f1)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(best_model, \"model\")\n",
        "    # Stocker les résultats dans un DataFrame\n",
        "    results = pd.DataFrame({\n",
        "        'Model': [best_model.__class__.__name__],\n",
        "        'Best Parameters': [random_search.best_params_],\n",
        "        'Training AUC': [random_search.best_score_],\n",
        "        'Test AUC': [auc],\n",
        "        'Precision': [precision],\n",
        "        'Recall': [recall],\n",
        "        'F1 Score': [f1], \n",
        "        'Training Recall': [train_score],\n",
        "        'Validation Recall': [validation_score],\n",
        "        'Test Recall': [test_score]\n",
        "    })\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 3-5 Randomforest, test hyperparamètres - pipeline preprocessing & classifier + ML FLow on recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/07/18 17:03:49 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
            "2023/07/18 17:03:50 WARNING mlflow.utils: Truncated the value of the key `param_distributions`. Truncated value: `{'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002006228F5E0>, 'classifier__max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000200622ADAE0>, 'classifier__class_weight': ['balanced', 'balanced_subsample'], 'classifier__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000200622AD450>, 'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen objec...`\n",
            "2023/07/18 17:03:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/18 17:11:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/18 17:11:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\sklearn\\utils.py:788: UserWarning: Top 5 child runs will be created based on ordering in rank_test_roc_auc column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
            "2023/07/18 17:11:44 INFO mlflow.sklearn.utils: Logging the 5 best runs, 20 runs will be omitted.\n",
            "2023/07/18 17:11:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/18 17:11:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    Model                                    Best Parameters  \\\n",
            "0  RandomForestClassifier  {'classifier__class_weight': 'balanced_subsamp...   \n",
            "\n",
            "   Training Recall  Validation Recall  Test Recall  Test AUC  Precision  \\\n",
            "0         0.676259           0.594156     0.671429  0.667006   0.097372   \n",
            "\n",
            "   F1 Score  \n",
            "0  0.175732  \n"
          ]
        }
      ],
      "source": [
        "# Read data\n",
        "sample_df = pd.read_csv('../data/sample_df.csv')\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "sample_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Separate the target from the rest of the data\n",
        "X = sample_df.drop(columns=[\"TARGET\"])\n",
        "y = sample_df['TARGET']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "### Setup MLFLOW\n",
        "mlflow.set_experiment('Scoring_models')\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('scaler', RobustScaler())\n",
        "])\n",
        "\n",
        "# Define classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Combine preprocessing and classifier into a single pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', clf)\n",
        "])\n",
        "\n",
        "# Define hyperparameters for the Random Forest Classifier\n",
        "param_dist = {\n",
        "    'classifier__n_estimators': randint(100, 200),\n",
        "    'classifier__max_depth': randint(1,5),\n",
        "    'classifier__class_weight': ['balanced', 'balanced_subsample'],\n",
        "    'classifier__min_samples_split': randint(20,40),\n",
        "    'classifier__min_samples_leaf': randint(10,40),\n",
        "    'classifier__max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "scorings = ['roc_auc', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, cv=5,n_jobs=-1, scoring=scorings, refit='recall', n_iter=25, random_state=42)\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run(run_name='Modelisation_recall_1'):\n",
        "\n",
        "    # Train the model\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Calculate train score\n",
        "    train_score = recall_score(y_train, best_model.predict(X_train))\n",
        "\n",
        "    # Calculate validation score\n",
        "    validation_score = random_search.best_score_\n",
        "\n",
        "    # Predict the labels of the test set\n",
        "    y_pred = random_search.predict(X_test)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_score = recall_score(y_test, y_pred)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    y_pred_proba = random_search.predict_proba(X_test)[:, 1]\n",
        "    threshold = 0.4\n",
        "    y_pred = (y_pred_proba > threshold).astype(int)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Log the parameters\n",
        "    mlflow.log_params(random_search.best_params_)\n",
        "\n",
        "    # Log the metrics\n",
        "    mlflow.log_metric(\"Training Recall\", train_score)\n",
        "    mlflow.log_metric(\"Validation Recall\", validation_score)\n",
        "    mlflow.log_metric(\"Test Recall\", test_score)\n",
        "    mlflow.log_metric(\"Test AUC\", auc)\n",
        "    mlflow.log_metric(\"Precision\", precision)\n",
        "    mlflow.log_metric(\"Recall\", recall)\n",
        "    mlflow.log_metric(\"F1 Score\", f1)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(best_model, \"model\")\n",
        "\n",
        "    # Store the results in a DataFrame\n",
        "    results = pd.DataFrame({\n",
        "        'Model': [random_search.best_estimator_.named_steps['classifier'].__class__.__name__],\n",
        "        'Best Parameters': [random_search.best_params_],\n",
        "        'Training Recall': [train_score],\n",
        "        'Validation Recall': [validation_score],\n",
        "        'Test Recall': [test_score],\n",
        "        'Test AUC': [auc],\n",
        "        'Precision': [precision],\n",
        "        'F1 Score': [f1] \n",
        "    })\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[209 584]\n",
            " [  7  63]]\n"
          ]
        }
      ],
      "source": [
        "cm_recall = confusion_matrix(y_test, y_pred)\n",
        "print(cm_recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 3-6 Randomforest, test hyperparamètres - pipeline preprocessing & classifier + ML FLow - score roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/07/18 17:28:39 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
            "2023/07/18 17:28:39 WARNING mlflow.utils: Truncated the value of the key `param_distributions`. Truncated value: `{'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002005DD6E3E0>, 'classifier__max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002005D651BD0>, 'classifier__class_weight': ['balanced', 'balanced_subsample'], 'classifier__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002005D652F20>, 'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen objec...`\n",
            "2023/07/18 17:28:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/18 17:54:08 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/18 17:54:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\sklearn\\utils.py:788: UserWarning: Top 5 child runs will be created based on ordering in rank_test_roc_auc column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
            "2023/07/18 17:54:18 INFO mlflow.sklearn.utils: Logging the 5 best runs, 30 runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    Model                                    Best Parameters  \\\n",
            "0  RandomForestClassifier  {'classifier__class_weight': 'balanced_subsamp...   \n",
            "\n",
            "   Training AUC  Validation AUC  Test AUC  Precision    Recall  F1 Score  \n",
            "0      0.984054        0.714826  0.704468    0.26087  0.257143  0.258993  \n"
          ]
        }
      ],
      "source": [
        "# Read data\n",
        "sample_df = pd.read_csv('../data/sample_df.csv')\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "sample_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Separate the target from the rest of the data\n",
        "X = sample_df.drop(columns=[\"TARGET\"])\n",
        "y = sample_df['TARGET']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "### Setup MLFLOW\n",
        "mlflow.set_experiment('Scoring_models')\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('scaler', RobustScaler())\n",
        "])\n",
        "\n",
        "# Define classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Combine preprocessing and classifier into a single pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', clf)\n",
        "])\n",
        "\n",
        "# Define hyperparameters for the Random Forest Classifier\n",
        "param_dist = {\n",
        "    'classifier__n_estimators': randint(150, 500),\n",
        "    'classifier__max_depth': randint(1,10),\n",
        "    'classifier__class_weight': ['balanced', 'balanced_subsample'],\n",
        "    'classifier__min_samples_split': randint(20,40),\n",
        "    'classifier__min_samples_leaf': randint(20,40),\n",
        "    'classifier__max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "scorings = ['roc_auc', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, cv=5, n_jobs=-1, scoring=scorings, refit='roc_auc', n_iter=35, random_state=42)\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run(run_name='Modelisation_auc_5'):\n",
        "\n",
        "    # Train the model\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Predict the labels of the test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Calculate training metrics\n",
        "    train_pred_proba = best_model.predict_proba(X_train)[:, 1]\n",
        "    train_pred = best_model.predict(X_train)\n",
        "    training_auc = roc_auc_score(y_train, train_pred_proba)\n",
        "    training_precision = precision_score(y_train, train_pred)\n",
        "    training_recall = recall_score(y_train, train_pred)\n",
        "    training_f1 = f1_score(y_train, train_pred)\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    validation_auc = random_search.best_score_\n",
        "\n",
        "    # Calculate test metrics\n",
        "    test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "    test_auc = roc_auc_score(y_test, test_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Log the parameters\n",
        "    mlflow.log_params(random_search.best_params_)\n",
        "\n",
        "    # Log the metrics\n",
        "    mlflow.log_metric(\"Training AUC\", training_auc)\n",
        "    mlflow.log_metric(\"Validation AUC\", validation_auc)\n",
        "    mlflow.log_metric(\"Test AUC\", test_auc)\n",
        "    mlflow.log_metric(\"Precision\", precision)\n",
        "    mlflow.log_metric(\"Recall\", recall)\n",
        "    mlflow.log_metric(\"F1 Score\", f1)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(best_model, \"model\")\n",
        "\n",
        "    # Store the results in a DataFrame\n",
        "    results = pd.DataFrame({\n",
        "        'Model': [random_search.best_estimator_.named_steps['classifier'].__class__.__name__],\n",
        "        'Best Parameters': [random_search.best_params_],\n",
        "        'Training AUC': [training_auc],\n",
        "        'Validation AUC': [validation_auc],\n",
        "        'Test AUC': [test_auc],\n",
        "        'Precision': [precision],\n",
        "        'Recall': [recall],\n",
        "        'F1 Score': [f1]\n",
        "    })\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[742  51]\n",
            " [ 52  18]]\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 3-7 - Randomforest, test hyperparamètres - pipeline preprocessing & classifier + ML FLow + SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/07/18 17:56:18 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
            "2023/07/18 17:56:18 WARNING mlflow.utils: Truncated the value of the key `param_distributions`. Truncated value: `{'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000200623555D0>, 'classifier__max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002005FA78820>, 'classifier__class_weight': ['balanced', 'balanced_subsample'], 'classifier__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002005FA7A380>, 'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen objec...`\n",
            "2023/07/18 17:56:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/18 18:13:15 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/18 18:13:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\sklearn\\utils.py:788: UserWarning: Top 5 child runs will be created based on ordering in rank_test_roc_auc column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
            "2023/07/18 18:13:19 INFO mlflow.sklearn.utils: Logging the 5 best runs, 30 runs will be omitted.\n",
            "2023/07/18 18:13:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/18 18:13:21 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    Model                                    Best Parameters  \\\n",
            "0  RandomForestClassifier  {'classifier__class_weight': 'balanced', 'clas...   \n",
            "\n",
            "   Training ROC AUC  Validation ROC AUC  Test ROC AUC  Test AUC  Precision  \\\n",
            "0          0.640933            0.668002       0.58675  0.670924   0.136076   \n",
            "\n",
            "     Recall  F1 Score  \n",
            "0  0.614286  0.222798  \n"
          ]
        }
      ],
      "source": [
        "from imblearn.pipeline import Pipeline as imbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Read data\n",
        "sample_df = pd.read_csv('../data/sample_df.csv')\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "sample_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Separate the target from the rest of the data\n",
        "X = sample_df.drop(columns=[\"TARGET\"])\n",
        "y = sample_df['TARGET']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "### Setup MLFLOW\n",
        "mlflow.set_experiment('Scoring_models')\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Define classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Combine preprocessing, SMOTE, and classifier into a single pipeline because we use imbleanr library (can't use pipeline on pipeline)\n",
        "pipeline = imbPipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('scaler', RobustScaler()),\n",
        "    ('smote', smote),\n",
        "    ('classifier', clf)\n",
        "])\n",
        "\n",
        "# Define hyperparameters for the Random Forest Classifier\n",
        "param_dist = {\n",
        "    'classifier__n_estimators': randint(100, 200),\n",
        "    'classifier__max_depth': randint(1, 5),\n",
        "    'classifier__class_weight': ['balanced', 'balanced_subsample'],\n",
        "    'classifier__min_samples_split': randint(20, 40),\n",
        "    'classifier__min_samples_leaf': randint(10, 40),\n",
        "    'classifier__max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "scorings = ['roc_auc', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, cv=5, n_jobs=-1, scoring=scorings, refit='roc_auc', n_iter=35)\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run(run_name='Modelisation_auc_smote_1'):\n",
        "\n",
        "    # Train the model\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Calculate train score\n",
        "    train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
        "\n",
        "    # Calculate validation score\n",
        "    validation_score = random_search.best_score_\n",
        "\n",
        "    # Predict the labels of the test set\n",
        "    y_pred = random_search.predict(X_test)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_score = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    y_pred_proba = random_search.predict_proba(X_test)[:, 1]\n",
        "    threshold = 0.4\n",
        "    y_pred = (y_pred_proba > threshold).astype(int)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Log the parameters\n",
        "    mlflow.log_params(random_search.best_params_)\n",
        "\n",
        "    # Log the metrics\n",
        "    mlflow.log_metric(\"Training ROC AUC\", train_score)\n",
        "    mlflow.log_metric(\"Validation ROC AUC\", validation_score)\n",
        "    mlflow.log_metric(\"Test ROC AUC\", test_score)\n",
        "    mlflow.log_metric(\"Test AUC\", auc)\n",
        "    mlflow.log_metric(\"Precision\", precision)\n",
        "    mlflow.log_metric(\"Recall\", recall)\n",
        "    mlflow.log_metric(\"F1 Score\", f1)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(best_model, \"model\")\n",
        "\n",
        "    # Store the results in a DataFrame\n",
        "    results = pd.DataFrame({\n",
        "        'Model': [random_search.best_estimator_.named_steps['classifier'].__class__.__name__],\n",
        "        'Best Parameters': [random_search.best_params_],\n",
        "        'Training ROC AUC': [train_score],\n",
        "        'Validation ROC AUC': [validation_score],\n",
        "        'Test ROC AUC': [test_score],\n",
        "        'Test AUC': [auc],\n",
        "        'Precision': [precision],\n",
        "        'Recall': [recall],\n",
        "        'F1 Score': [f1]\n",
        "    })\n",
        "\n",
        "print(results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[520 273]\n",
            " [ 27  43]]\n"
          ]
        }
      ],
      "source": [
        "cm_smote = confusion_matrix(y_test, y_pred)\n",
        "print(cm_smote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 3-8 - Randomforest, test hyperparamètres - pipeline preprocessing & classifier + ML FLow + SMOTE - métric métier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/07/25 13:27:43 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
            "2023/07/25 13:27:43 WARNING mlflow.utils: Truncated the value of the key `param_distributions`. Truncated value: `{'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B5B90BC0A0>, 'classifier__max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B5C0A15630>, 'classifier__class_weight': ['balanced', 'balanced_subsample'], 'classifier__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B5C0A16380>, 'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen objec...`\n",
            "2023/07/25 13:27:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/25 13:48:41 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
            "2023/07/25 13:48:51 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
            "2023/07/25 13:48:53 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\sklearn\\utils.py:788: UserWarning: Top 5 child runs will be created based on ordering in rank_test_roc_auc column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
            "2023/07/25 13:48:53 INFO mlflow.sklearn.utils: Logging the 5 best runs, 30 runs will be omitted.\n",
            "2023/07/25 13:48:54 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    Model                                    Best Parameters  \\\n",
            "0  RandomForestClassifier  {'classifier__class_weight': 'balanced', 'clas...   \n",
            "\n",
            "   Training ROC AUC  Validation ROC AUC  Test ROC AUC  Test AUC  Precision  \\\n",
            "0          0.640998            0.663805      0.582967  0.668618   0.133987   \n",
            "\n",
            "     Recall  F1 Score  Training Custom Metric  Test Custom Metric  \n",
            "0  0.585714  0.218085                0.334009            0.234067  \n"
          ]
        }
      ],
      "source": [
        "from imblearn.pipeline import Pipeline as imbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import make_scorer, confusion_matrix\n",
        "\n",
        "# Custom metric\n",
        "def custom_cost_only_fn(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    Profit_bycustomer = (1*tn - 10*fn) / y_true.shape[0]\n",
        "    return Profit_bycustomer\n",
        "\n",
        "custom_scorer_fn_only = make_scorer(custom_cost_only_fn, greater_is_better=True)\n",
        "\n",
        "# Read data\n",
        "sample_df = pd.read_csv('../data/sample_df.csv')\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "sample_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Separate the target from the rest of the data\n",
        "X = sample_df.drop(columns=[\"TARGET\"])\n",
        "y = sample_df['TARGET']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Setup MLFLOW\n",
        "mlflow.set_experiment('Scoring_models')\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Define classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Combine preprocessing, SMOTE, and classifier into a single pipeline\n",
        "pipeline = imbPipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('scaler', RobustScaler()),\n",
        "    ('smote', smote),\n",
        "    ('classifier', clf)\n",
        "])\n",
        "\n",
        "# Define hyperparameters for the Random Forest Classifier\n",
        "param_dist = {\n",
        "    'classifier__n_estimators': randint(100, 200),\n",
        "    'classifier__max_depth': randint(1, 5),\n",
        "    'classifier__class_weight': ['balanced', 'balanced_subsample'],\n",
        "    'classifier__min_samples_split': randint(20, 40),\n",
        "    'classifier__min_samples_leaf': randint(10, 40),\n",
        "    'classifier__max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Add your custom scorer to the list of scorings\n",
        "scorings = {\n",
        "    'roc_auc': 'roc_auc',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1',\n",
        "    'custom_score': custom_scorer_fn_only\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV with your custom scorer\n",
        "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, cv=5, n_jobs=-1, scoring=scorings, refit='roc_auc', n_iter=35)\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run(run_name='Modelisation_custom_metric_4'):\n",
        "\n",
        "    # Train the model\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Calculate train score\n",
        "    train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
        "\n",
        "    # Calculate validation score\n",
        "    validation_score = random_search.best_score_\n",
        "\n",
        "    # Predict the labels of the test set\n",
        "    y_pred = random_search.predict(X_test)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_score = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate custom metric\n",
        "    test_custom_cost = custom_cost_only_fn(y_test, y_pred)\n",
        "\n",
        "    # Calculate custom metric for the training set\n",
        "    train_custom_cost = custom_cost_only_fn(y_train, best_model.predict(X_train))\n",
        "\n",
        "    # Predict the probabilities of the test set\n",
        "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "    threshold = 0.4\n",
        "    y_pred = (y_pred_proba > threshold).astype(int)\n",
        "\n",
        "    # Calculate other metrics\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Log the parameters\n",
        "    mlflow.log_params(random_search.best_params_)\n",
        "\n",
        "    # Log the metrics\n",
        "    mlflow.log_metric(\"Training ROC AUC\", train_score)\n",
        "    mlflow.log_metric(\"Validation ROC AUC\", validation_score)\n",
        "    mlflow.log_metric(\"Test ROC AUC\", test_score)\n",
        "    mlflow.log_metric(\"Test AUC\", auc)\n",
        "    mlflow.log_metric(\"Precision\", precision)\n",
        "    mlflow.log_metric(\"Recall\", recall)\n",
        "    mlflow.log_metric(\"F1 Score\", f1)\n",
        "    mlflow.log_metric(\"Training Custom Metric\", train_custom_cost)\n",
        "    mlflow.log_metric(\"Test Custom Metric\", test_custom_cost)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(best_model, \"model\")\n",
        "\n",
        "    # Store the results in a DataFrame\n",
        "    results = pd.DataFrame({\n",
        "        'Model': [random_search.best_estimator_.named_steps['classifier'].__class__.__name__],\n",
        "        'Best Parameters': [random_search.best_params_],\n",
        "        'Training ROC AUC': [train_score],\n",
        "        'Validation ROC AUC': [validation_score],\n",
        "        'Test ROC AUC': [test_score],\n",
        "        'Test AUC': [auc],\n",
        "        'Precision': [precision],\n",
        "        'Recall': [recall],\n",
        "        'F1 Score': [f1],\n",
        "        'Training Custom Metric': [train_custom_cost],\n",
        "        'Test Custom Metric': [test_custom_cost]\n",
        "    })\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importance des features locales "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Numba needs NumPy 1.24 or less",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Importer la bibliothèque SHAP\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshap\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Initialiser le \"Tree Explainer\" de SHAP\u001b[39;00m\n\u001b[0;32m      5\u001b[0m explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mTreeExplainer(best_model\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      3\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.42.1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_explanation\u001b[39;00m \u001b[39mimport\u001b[39;00m Explanation, Cohorts\n\u001b[0;32m      7\u001b[0m \u001b[39m# explainers\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexplainers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_explainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Explainer\n",
            "File \u001b[1;32mc:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\_explanation.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mslicer\u001b[39;00m \u001b[39mimport\u001b[39;00m Alias, Obj, Slicer\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_exceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DimensionError\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_general\u001b[39;00m \u001b[39mimport\u001b[39;00m OpChain\n\u001b[0;32m     16\u001b[0m \u001b[39m# slicer confuses pylint...\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# pylint: disable=no-member\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\utils\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_clustering\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     delta_minimization_order,\n\u001b[0;32m      3\u001b[0m     hclust,\n\u001b[0;32m      4\u001b[0m     hclust_ordering,\n\u001b[0;32m      5\u001b[0m     partition_tree,\n\u001b[0;32m      6\u001b[0m     partition_tree_shuffle,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_general\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     OpChain,\n\u001b[0;32m     10\u001b[0m     approximate_interactions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     suppress_stderr,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_masked_model\u001b[39;00m \u001b[39mimport\u001b[39;00m MaskedModel, make_masks\n",
            "File \u001b[1;32mc:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\utils\\_clustering.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumba\u001b[39;00m \u001b[39mimport\u001b[39;00m njit\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_general\u001b[39;00m \u001b[39mimport\u001b[39;00m safe_isinstance\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_show_progress\u001b[39;00m \u001b[39mimport\u001b[39;00m show_progress\n",
            "File \u001b[1;32mc:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\__init__.py:55\u001b[0m\n\u001b[0;32m     50\u001b[0m             msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mNumba requires SciPy version 1.0 or greater. Got SciPy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mscipy\u001b[39m.\u001b[39m__version__\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[1;32m---> 55\u001b[0m _ensure_critical_deps()\n\u001b[0;32m     56\u001b[0m \u001b[39m# END DO NOT MOVE\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_version\u001b[39;00m \u001b[39mimport\u001b[39;00m get_versions\n",
            "File \u001b[1;32mc:\\Users\\DalilaDerdar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\__init__.py:42\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m     41\u001b[0m \u001b[39melif\u001b[39;00m numpy_version \u001b[39m>\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m24\u001b[39m):\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumba needs NumPy 1.24 or less\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n",
            "\u001b[1;31mImportError\u001b[0m: Numba needs NumPy 1.24 or less"
          ]
        }
      ],
      "source": [
        "# Importer la bibliothèque SHAP\n",
        "import shap\n",
        "\n",
        "# Initialiser le \"Tree Explainer\" de SHAP\n",
        "explainer = shap.TreeExplainer(best_model.named_steps['classifier'])\n",
        "\n",
        "# Calculer les valeurs SHAP pour les features de votre ensemble de test\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Visualiser les valeurs SHAP pour la première prédiction\n",
        "shap.initjs()\n",
        "\n",
        "# Afficher le graphique\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1][0,:], X_test.iloc[0,:])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
